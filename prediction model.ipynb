{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from scipy.signal import resample\n",
    "print(plt.style.available)  # List available styles\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FRAMES = True\n",
    "fem_path = r'Female_features.csv'\n",
    "mal_path = r'Male_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESS - 2,800\n",
    "TESS = r\"TESS  data\"\n",
    "#RAVDESS - 2,076\n",
    "RAV = r\"ravdess_speech_actors_01-24\"\n",
    "#SAVEE - 480\n",
    "SAVEE = r\"savee\"\n",
    "#CREMA-D - 7,442\n",
    "CREMA = r\"Crema D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data location for SAVEE\n",
    "dir_list = os.listdir(SAVEE)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('angry')\n",
    "    elif i[-8:-6]=='_d':       \n",
    "       emotion.append('disgust')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('fear')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('happy')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('neutral')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('sad')\n",
    "    elif i[-8:-6]=='su':\n",
    "      emotion.append('surprise')\n",
    "    else:\n",
    "        emotion.append('unknown') \n",
    "    path.append(SAVEE + i)\n",
    "\n",
    "# # Now check out the label count distribution \n",
    "#SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "#SAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "#print('SAVEE dataset')\n",
    "#SAVEE_df.head()\n",
    "#Create DataFrame\n",
    "SAVEE_df = pd.DataFrame({'labels': emotion, 'path': path})\n",
    "\n",
    "# Filter out rows with labels not equal to 'unknown'\n",
    "SAVEE_df = SAVEE_df[SAVEE_df['labels'] != 'unknown']\n",
    "\n",
    "print('SAVEE dataset')\n",
    "SAVEE_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SAVEE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data location for TESS\n",
    "path = []\n",
    "emotion = []\n",
    "dir_list = os.listdir(TESS)\n",
    "\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(os.path.join(TESS, i))  \n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "            emotion.append('angry')\n",
    "            \n",
    "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "           emotion.append('disgust')\n",
    "        elif i == 'OAF_Fear' or i == 'YAF_fear':           \n",
    "           emotion.append('fear')\n",
    "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "            emotion.append('happy')\n",
    "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "            emotion.append('neutral')                                \n",
    "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':             \n",
    "             emotion.append('surprise')               \n",
    "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "            emotion.append('sad')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(TESS + i + \"/\" + f)\n",
    "TESS_df = pd.DataFrame({'labels': emotion, 'path': path})\n",
    "\n",
    "# Filter out rows with labels not equal to 'Unknown'\n",
    "TESS_df = TESS_df[TESS_df['labels'] != 'Unknown']\n",
    "\n",
    "#TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "#TESS_df['source'] = 'TESS'\n",
    "#TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "print('TESS dataset')\n",
    "TESS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TESS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datas from RAVDESS\n",
    "dir = os.listdir(RAV)\n",
    "\n",
    "males = []\n",
    "females = [] \n",
    "        \n",
    "for actor in dir:\n",
    "       \n",
    "    files = os.listdir(os.path.join(RAV, actor))\n",
    "        \n",
    "    for file in files: \n",
    "        part = file.split('.')[0]\n",
    "        part = part.split(\"-\")\n",
    "        temp = int(part[6])        \n",
    "                \n",
    "        if part[2] == '01':\n",
    "            emotion = 'neutral'\n",
    "        elif part[2] == '03':\n",
    "            emotion = 'happy'\n",
    "        elif part[2] == '04':\n",
    "            emotion = 'sad'\n",
    "        elif part[2] == '05':\n",
    "            emotion = 'angry'\n",
    "        else:\n",
    "            emotion = 'unknown'\n",
    "        if temp%2 == 0:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "            #emotion = 'female_'+emotion\n",
    "            females.append([emotion, path]) \n",
    "        else:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "             #emotion = 'male_'+emotion\n",
    "            males.append([emotion, path])\n",
    "\n",
    "# Create DataFrames\n",
    "RavFemales_df = pd.DataFrame(females, columns=['labels', 'path'])\n",
    "RavMales_df = pd.DataFrame(males, columns=['labels', 'path'])\n",
    "\n",
    "# Filter out rows with labels not equal to 'unknown'\n",
    "RavFemales_df = RavFemales_df[RavFemales_df['labels'] != 'unknown']\n",
    "RavMales_df = RavMales_df[RavMales_df['labels'] != 'unknown']\n",
    "\n",
    "print('RAVDESS datasets - Females')\n",
    "RavFemales_df.head()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RavFemales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRAVDESS datasets - Males')\n",
    "RavMales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RavMales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datas from RAVDESS\n",
    "dir = os.listdir(RAV)\n",
    "\n",
    "males = []\n",
    "females = [] \n",
    "        \n",
    "for actor in dir:\n",
    "       \n",
    "    files = os.listdir(os.path.join(RAV, actor))\n",
    "        \n",
    "    for file in files: \n",
    "        part = file.split('.')[0]\n",
    "        part = part.split(\"-\")\n",
    "        temp = int(part[6])        \n",
    "                \n",
    "        if part[2] == '01':\n",
    "            emotion = 'neutral'\n",
    "        elif part[2] == '02':\n",
    "             emotion = 'calm'\n",
    "        elif part[2] == '03':\n",
    "            emotion = 'happy'\n",
    "        elif part[2] == '04':\n",
    "            emotion = 'sad'\n",
    "        elif part[2] == '05':\n",
    "            emotion = 'angry'\n",
    "        elif part[2] == '06':\n",
    "             emotion = 'fear'\n",
    "        elif part[2] == '07':\n",
    "             emotion = 'disgust'\n",
    "        elif part[2] == '08':\n",
    "             emotion = 'surprise'\n",
    "        else:\n",
    "            emotion = 'unknown'\n",
    "            \n",
    "        if temp%2 == 0:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "            #emotion = 'female_'+emotion\n",
    "            females.append([emotion, path]) \n",
    "        else:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "             #emotion = 'male_'+emotion\n",
    "            males.append([emotion, path])\n",
    "\n",
    "# RavFemales_df = pd.DataFrame(females)\n",
    "# RavFemales_df.columns = ['labels', 'path']\n",
    "\n",
    "# RavMales_df = pd.DataFrame(males)\n",
    "# RavMales_df.columns = ['labels', 'path']\n",
    "\n",
    "# print('RAVDESS datasets')\n",
    "# RavFemales_df.head()\n",
    "# Create DataFrames\n",
    "RavFemales_df = pd.DataFrame(females, columns=['labels', 'path'])\n",
    "RavMales_df = pd.DataFrame(males, columns=['labels', 'path'])\n",
    "\n",
    "# Filter out rows with labels not equal to 'unknown'\n",
    "RavFemales_df = RavFemales_df[RavFemales_df['labels'] != 'unknown']\n",
    "RavMales_df = RavMales_df[RavMales_df['labels'] != 'unknown']\n",
    "\n",
    "print('RAVDESS datasets - Females')\n",
    "RavFemales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRAVDESS datasets - Males')\n",
    "RavMales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RavMales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(CREMA)\n",
    "\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "males = []\n",
    "females = []\n",
    "\n",
    "for file in files: \n",
    "    part = file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        emotion = 'sad'\n",
    "    elif part[2] == 'ANG':\n",
    "        emotion = 'angry'\n",
    "    elif part[2] == 'DIS':\n",
    "         emotion = 'disgust'\n",
    "    elif part[2] == 'FEA':\n",
    "        emotion = 'fear'\n",
    "    elif part[2] == 'HAP':\n",
    "        emotion = 'happy'\n",
    "    elif part[2] == 'NEU':\n",
    "        emotion = 'neutral'  \n",
    "    else:\n",
    "        emotion = 'unknown'\n",
    "\n",
    "    if int(part[0]) in female:\n",
    "        path = (CREMA + '/' + file)\n",
    "        #emotion = 'female_'+emotion\n",
    "        females.append([emotion, path]) \n",
    "    else:\n",
    "        path = (CREMA + '/' + file)\n",
    "        #emotion = 'male_'+emotion\n",
    "        males.append([emotion, path])\n",
    "\n",
    "CremaFemales_df = pd.DataFrame(females)\n",
    "CremaFemales_df.columns = ['labels', 'path']\n",
    "\n",
    "CremaMales_df = pd.DataFrame(males)\n",
    "CremaMales_df.columns = ['labels', 'path']\n",
    "    \n",
    "print('CREMA datasets')\n",
    "CremaFemales_df.head()\n",
    "\n",
    "#Create DataFrames\n",
    "CremaFemales_df = pd.DataFrame(females, columns=['labels', 'path'])\n",
    "CremaMales_df = pd.DataFrame(males, columns=['labels', 'path'])\n",
    "\n",
    "# Filter out rows with labels not equal to 'unknown'\n",
    "CremaFemales_df = CremaFemales_df[CremaFemales_df['labels'] != 'unknown']\n",
    "CremaMales_df = CremaMales_df[CremaMales_df['labels'] != 'unknown']\n",
    "\n",
    "print('CREMA datasets - Females')\n",
    "CremaFemales_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CremaMales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nCREMA datasets - Males')\n",
    "CremaMales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CremaMales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets merge all the dataframe\n",
    "Males = pd.concat([SAVEE_df, RavMales_df, CremaMales_df], axis = 0)\n",
    "Males.to_csv(\"males_emotions_df.csv\", index = False)\n",
    "\n",
    "Females = pd.concat([TESS_df, RavFemales_df, CremaFemales_df], axis = 0)\n",
    "Females.to_csv(\"females_emotions_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming Females.labels and Males.labels are lists or arrays\n",
    "# Convert them to pandas Series\n",
    "Females_labels_series = pd.Series(Females.labels)\n",
    "Males_labels_series = pd.Series(Males.labels)\n",
    "\n",
    "# Define the order of emotions\n",
    "order = ['angry', 'calm', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "#order = ['angry', 'happy', 'neutral', 'sad']\n",
    "\n",
    "# Create subplots\n",
    "fig = plt.figure(figsize=(17, 5))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "plt.title('Count of Females Emotions', size=16)\n",
    "Females_labels_series.value_counts().loc[order].plot(kind='bar')\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "fig.add_subplot(122)\n",
    "plt.title('Count of Males Emotions', size=16)\n",
    "Males_labels_series.value_counts().loc[order].plot(kind='bar')\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f'Waveplot for audio with {e} emotion', size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'Angry'\n",
    "path = r'\\Users\\shivd\\Downloads\\speech_emotion_detection\\ravdess\\ravdess_speech_actors_01-24\\Actor_01\\03-01-05-01-01-01-01.wav'\n",
    "plt.figure(figsize=(10, 3))\n",
    "data, sampling_rate = librosa.load(path)\n",
    "librosa.display.waveshow(data, sr=sampling_rate, color='blue')\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion='Very Angry' \n",
    "path = r'\\Users\\shivd\\Downloads\\speech_emotion_detection\\ravdess\\ravdess_speech_actors_01-24/Actor_01/03-01-05-02-01-01-01.wav'\n",
    "plt.figure(figsize=(10, 3))\n",
    "data, sampling_rate = librosa.load(path)\n",
    "librosa.display.waveshow(data, sr=sampling_rate, color='red')\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion='Sing Angry'\n",
    "path = r'\\Users\\shivd\\Downloads\\speech_emotion_detection\\ravdess\\ravdess_song_actors_01-24/Actor_01/03-02-05-01-01-01-01.wav'\n",
    "plt.figure(figsize=(10, 3))\n",
    "data, sampling_rate = librosa.load(path)\n",
    "librosa.display.waveshow(data, sr=sampling_rate, color='red')\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion='Sing Very Angry' \n",
    "path = r'\\Users\\shivd\\Downloads\\speech_emotion_detection\\ravdess\\ravdess_song_actors_01-24/Actor_01/03-02-05-02-01-01-01.wav'\n",
    "plt.figure(figsize=(10, 3))\n",
    "data, sampling_rate = librosa.load(path)\n",
    "librosa.display.waveshow(data, sr=sampling_rate, color='red')\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def lower_speed(data, speed_factor = 0.75):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "# taking any example and checking for techniques.\n",
    "path = path = r'\\Users\\shivd\\Downloads\\speech_emotion_detection\\ravdess\\ravdess_speech_actors_01-24/Actor_01/03-01-05-01-01-01-01.wav'\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming noise() is a function you've defined to add noise to data\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = noise(data)  # Applying noise to the data\n",
    "y = resample(x, len(data))  # Resampling the noisy data to match original length\n",
    "librosa.display.waveshow(y, sr=sample_rate, color=\"blue\")\n",
    "plt.title('Waveplot with Noise', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio with added noise\n",
    "Audio(y, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = stretch(data)  # Assuming data is loaded or defined elsewhere\n",
    "librosa.display.waveshow(y=x, sr=sample_rate, color=\"green\")\n",
    "plt.title('Waveplot with Time Stretching', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio after time stretching\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(data, n_steps=2):\n",
    "    return librosa.effects.pitch_shift(data, sr=sample_rate, n_steps=n_steps)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = shift(data)  # Assuming data is loaded or defined elsewhere\n",
    "librosa.display.waveshow(y=x, sr=sample_rate, color=\"blue\")\n",
    "plt.title('Waveplot with Pitch Shifting', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio after pitch shifting\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, n_steps=int(pitch_factor * 12), sr=sampling_rate)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = pitch(data, sample_rate)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate, color=\"blue\")\n",
    "plt.title('Waveplot with Pitch Shifting', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio after pitch shifting\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_speed(data, sample_rate, speed_factor=1.25):\n",
    "    return librosa.effects.time_stretch(y=data, rate=speed_factor)\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = higher_speed(data, sample_rate)  # Assuming data and sample_rate are defined elsewhere\n",
    "librosa.display.waveshow(y=x, sr=sample_rate,color=\"blue\")\n",
    "plt.title('Waveplot with Increased Speed', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio after increasing the speed\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_speed(data, speed_factor=0.75):\n",
    "    return librosa.effects.time_stretch(data, rate=speed_factor)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "x = lower_speed(data)  # Assuming data and sample_rate are defined elsewhere\n",
    "librosa.display.waveshow(y=x, sr=sample_rate, color=\"blue\")\n",
    "plt.title('Waveplot with Decreased Speed', size=15)\n",
    "plt.show()\n",
    "\n",
    "# Playing the audio after decreasing the speed\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_rate = 22050\n",
    "\n",
    "def extract_features(data):\n",
    "    \n",
    "    result = np.array([])\n",
    "    \n",
    "    #mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=42) #42 mfcc so we get frames of ~60 ms\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "     \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=3, offset=0.5, res_type='kaiser_fast') \n",
    "    \n",
    "    #without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    #noised\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    #stretched\n",
    "    stretch_data = stretch(data)\n",
    "    res3 = extract_features(stretch_data)\n",
    "    result = np.vstack((result, res3))\n",
    "    \n",
    "    #shifted\n",
    "    shift_data = shift(data)\n",
    "    res4 = extract_features(shift_data)\n",
    "    result = np.vstack((result, res4))\n",
    "    \n",
    "    #pitched\n",
    "    pitch_data = pitch(data, sample_rate)\n",
    "    res5 = extract_features(pitch_data)\n",
    "    result = np.vstack((result, res5))\n",
    "\n",
    "    #speed up\n",
    "    higher_speed_data = higher_speed(data)\n",
    "    res6 = extract_features(higher_speed_data)\n",
    "    result = np.vstack((result, res6))\n",
    "    \n",
    "    #speed down\n",
    "    lower_speed_data = higher_speed(data)\n",
    "    res7 = extract_features(lower_speed_data)\n",
    "    result = np.vstack((result, res7))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FRAMES:\n",
    "    \n",
    "    valid_emotions = ['angry', 'happy', 'neutral', 'sad']\n",
    "\n",
    "    female_X, female_Y = [], []\n",
    "    for path, emotion in zip(Females.path, Females.labels):\n",
    "        if emotion in valid_emotions:\n",
    "            features = get_features(path)\n",
    "            # adding augmentation, get_features return a multi-dimensional array (for each augmentation),\n",
    "            # so we have to use a loop to fill the df\n",
    "            for elem in features:\n",
    "                female_X.append(elem)\n",
    "                female_Y.append(emotion)\n",
    "\n",
    "    male_X, male_Y = [], []\n",
    "    for path, emotion in zip(Males.path, Males.labels):\n",
    "        if emotion in valid_emotions:\n",
    "            features = get_features(path)\n",
    "            for elem in features:\n",
    "                male_X.append(elem)\n",
    "                male_Y.append(emotion)\n",
    "\n",
    "    print(f'Check shapes:\\nFemale features: {len(female_X)}, labels: {len(female_Y)}\\nMale features:   {len(male_X)}, labels: {len(male_Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FRAMES:\n",
    "    \n",
    "    female_X, female_Y = [], []\n",
    "    for path, emotion in zip(Females.path, Females.labels):\n",
    "        features = get_features(path)\n",
    "        #adding augmentation, get_features return a multi dimensional array (for each augmentation), so we have to use a loop to fill the df\n",
    "        for elem in features: \n",
    "            female_X.append(elem)        \n",
    "            female_Y.append(emotion)\n",
    "\n",
    "    male_X, male_Y = [], []\n",
    "    for path, emotion in zip(Males.path, Males.labels):\n",
    "        features = get_features(path)\n",
    "        for elem in features:\n",
    "            male_X.append(elem)\n",
    "            male_Y.append(emotion)\n",
    "            \n",
    "    print(f'Check shapes:\\nFemale features: {len(female_X)}, labels: {len(female_Y)}\\nMale features:   {len(male_X)}, labels: {len(male_Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataframe(gender, features, labels):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['labels'] = labels\n",
    "    \n",
    "    # Filter only the desired labels\n",
    "    valid_labels = ['angry', 'happy', 'neutral', 'sad']\n",
    "    df = df[df['labels'].isin(valid_labels)]\n",
    "\n",
    "    df.to_csv(f'{gender}_features.csv', index=False)\n",
    "    \n",
    "    print(f'{gender} dataframe')\n",
    "    df.sample(frac=1).head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataframe(gender, features, labels):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['labels'] = labels\n",
    "    df.to_csv(f'{gender}_features.csv', index=False)\n",
    "    \n",
    "    print(f'{gender} dataframe')\n",
    "    df.sample(frac=1).head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not DATA_FRAMES:\n",
    " #   valid_emotions = ['angry', 'happy', 'neutral', 'sad']\n",
    "\n",
    " #   female_X, female_Y = [], []\n",
    " #   for path, emotion in zip(Females.path, Females.labels):\n",
    " #       if emotion in valid_emotions:\n",
    "  #          features = get_features(path)\n",
    "#             # adding augmentation, get_features return a multi-dimensional array (for each augmentation),\n",
    "#             # so we have to use a loop to fill the df\n",
    "  #          for elem in features:\n",
    " #               female_X.append(elem)\n",
    " #               female_Y.append(emotion)\n",
    "\n",
    "#  Females_Features = setup_dataframe('Female', female_X, female_Y)\n",
    "#else:\n",
    "#   Females_Features = pd.read_csv(fem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FRAMES:\n",
    "    Females_Features = setup_dataframe('Female', female_X, female_Y)\n",
    "else:\n",
    "    Females_Features = pd.read_csv(fem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FRAMES:\n",
    "    valid_emotions = ['angry', 'happy', 'neutral', 'sad']\n",
    "\n",
    "    male_X, male_Y = [], []\n",
    "    for path, emotion in zip(Males.path, Males.labels):\n",
    "        if emotion in valid_emotions:\n",
    "            features = get_features(path)\n",
    "            # adding augmentation, get_features return a multi-dimensional array (for each augmentation),\n",
    "#             # so we have to use a loop to fill the df\n",
    "            for elem in features:\n",
    "                male_X.append(elem)\n",
    "                male_Y.append(emotion)\n",
    "\n",
    "    Males_Features = setup_dataframe('Male', male_X, male_Y)\n",
    "# else:\n",
    "    Males_Features = pd.read_csv(mal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FRAMES:\n",
    "    Males_Features = setup_dataframe('Male', male_X, male_Y)\n",
    "else:\n",
    "    Males_Features = pd.read_csv(mal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_X = Females_Features.iloc[: ,:-1].values\n",
    "female_Y = Females_Features['labels'].values\n",
    "\n",
    "male_X = Males_Features.iloc[: ,:-1].values\n",
    "male_Y = Males_Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = ['angry', 'happy', 'neutral', 'sad']\n",
    "\n",
    "# For Females\n",
    "female_X = Females_Features[Females_Features['labels'].isin(valid_labels)].iloc[:, :-1].values\n",
    "female_Y = Females_Features[Females_Features['labels'].isin(valid_labels)]['labels'].values\n",
    "\n",
    "# For Males\n",
    "male_X = Males_Features[Males_Features['labels'].isin(valid_labels)].iloc[:, :-1].values\n",
    "male_Y = Males_Features[Males_Features['labels'].isin(valid_labels)]['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y.\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "female_Y = encoder.fit_transform(np.array(female_Y).reshape(-1,1)).toarray()\n",
    "male_Y = encoder.fit_transform(np.array(male_Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING DATA\n",
    "nogender_X = np.concatenate((female_X, male_X))\n",
    "nogender_Y = np.concatenate((female_Y, male_Y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(nogender_X, nogender_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainF, x_testF, y_trainF, y_testF = train_test_split(female_X, female_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "x_trainF.shape, y_trainF.shape, x_testF.shape, y_testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainM, x_testM, y_trainM, y_testM = train_test_split(male_X, male_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "x_trainM.shape, y_trainM.shape, x_testM.shape, y_testM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_trainF = scaler.fit_transform(x_trainF)\n",
    "x_testF = scaler.transform(x_testF)\n",
    "\n",
    "x_trainM = scaler.fit_transform(x_trainM)\n",
    "x_testM = scaler.transform(x_testM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape , x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainF = np.expand_dims(x_trainF, axis=2)\n",
    "x_testF = np.expand_dims(x_testF, axis=2)\n",
    "x_trainF.shape, y_trainF.shape, x_testF.shape, y_testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainM = np.expand_dims(x_trainM, axis=2)\n",
    "x_testM = np.expand_dims(x_testM, axis=2)\n",
    "x_trainM.shape, y_trainM.shape, x_testM.shape, y_testM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, utils, callbacks\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, AveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    def build_model(in_shape):\n",
    "        \n",
    "        model=Sequential()\n",
    "        model.add(Conv1D(256, kernel_size=6, strides=1, padding='same', activation='relu', input_shape=(in_shape, 1)))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "\n",
    "        model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "\n",
    "        model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv1D(64, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(units=4, activation='softmax'))\n",
    "        model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "          \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_summary(mod_dim, tr_features, val_features, val_labels):\n",
    "    model = build_model(mod_dim)\n",
    "    model.summary()\n",
    "    \n",
    "    score = model.evaluate(val_features, val_labels, verbose = 1)\n",
    "    accuracy = 100*score[1]\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=4, min_lr=0.000001)\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graphs(history):\n",
    "    epochs = [i for i in range(n_epochs)]\n",
    "    fig , ax = plt.subplots(1,2)\n",
    "    train_acc = history.history['accuracy']\n",
    "    train_loss = history.history['loss']\n",
    "    test_acc = history.history['val_accuracy']\n",
    "    test_loss = history.history['val_loss']\n",
    "\n",
    "    fig.set_size_inches(30,12)\n",
    "    ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "    ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "    ax[0].set_title('Training & Testing Loss')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "    ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "    ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "    ax[1].set_title('Training & Testing Accuracy')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model = model_build_summary(x_train.shape[1], x_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_model = model_build_summary(x_trainF.shape[1], x_trainF, x_testF, y_testF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_model = model_build_summary(x_trainM.shape[1], x_trainM, x_testM, y_testM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "history = total_model.fit(x_train, y_train, batch_size=batch_size, epochs=NUM_EPOCHS, validation_data=(x_test, y_test), callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "female_history = female_model.fit(x_trainF, y_trainF, batch_size=batch_size, epochs=NUM_EPOCHS, validation_data=(x_testF, y_testF), callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "male_history = male_model.fit(x_trainM, y_trainM, batch_size=batch_size, epochs=NUM_EPOCHS, validation_data=(x_testM, y_testM), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "\n",
    "layer_name = 'conv1d_4'\n",
    "intermediate_layer_model = keras.Model(inputs=female_model.input,\n",
    "                                       outputs=female_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model(x_testF)\n",
    "print(intermediate_output[1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genderless\n",
    "score = total_model.evaluate(x_train,y_train, verbose = 0)\n",
    "print(\"Mixed-gender emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "score = total_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Mixed-gender emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = female_model.evaluate(x_trainF,y_trainF, verbose = 0)\n",
    "print(\"Female emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "score = female_model.evaluate(x_testF, y_testF, verbose=0)\n",
    "print(\"Female emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = male_model.evaluate(x_trainM,y_trainM, verbose = 0)\n",
    "print(\"Male emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "score = male_model.evaluate(x_testM, y_testM, verbose=0)\n",
    "print(\"Male emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_graphs(history):\n",
    "    # Extract training and validation loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'history' contains your training history\n",
    "show_graphs(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_graphs(history):\n",
    "    # Extract training and validation loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'female_history' contains your training history\n",
    "show_graphs(female_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_graphs(history):\n",
    "    # Extract training and validation loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'male_history' contains your training history\n",
    "show_graphs(male_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion matrix\n",
    "# predicting on test data.\n",
    "pred_test = female_model.predict(x_testF)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "y_test_ = encoder.inverse_transform(y_testF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_, y_pred)\n",
    "plt.figure(figsize = (8, 6))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix for Female Emotions', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test = male_model.predict(x_testM)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "y_test_ = encoder.inverse_transform(y_testM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_, y_pred)\n",
    "plt.figure(figsize = (8, 6))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix for Male Emotions', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming 'female_model' is your trained female emotion model\n",
    "# Assuming 'x_testF' and 'y_testF' are your test features and labels for females\n",
    "pred_test_female = female_model.predict(x_testF)\n",
    "y_pred_female = encoder.inverse_transform(pred_test_female)\n",
    "y_test_female = encoder.inverse_transform(y_testF)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_report_female = classification_report(y_test_female, y_pred_female)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report for Female Emotions:\")\n",
    "print(classification_report_female)\n",
    "\n",
    "# Repeat the process for the male emotion model and data\n",
    "# Assuming 'male_model' is your trained male emotion model\n",
    "# Assuming 'x_testM' and 'y_testM' are your test features and labels for males\n",
    "pred_test_male = male_model.predict(x_testM)\n",
    "y_pred_male = encoder.inverse_transform(pred_test_male)\n",
    "y_test_male = encoder.inverse_transform(y_testM)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_report_male = classification_report(y_test_male, y_pred_male)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report for Male Emotions:\")\n",
    "print(classification_report_male)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'female_model' is your trained female emotion model\n",
    "# Assuming 'x_testF' and 'y_testF' are your test features and labels for females\n",
    "# Assuming 'encoder' is the OneHotEncoder used for encoding labels\n",
    "\n",
    "# Get predictions for female model\n",
    "pred_test_female = female_model.predict(x_testF)\n",
    "y_pred_female = encoder.inverse_transform(pred_test_female)\n",
    "y_test_female = encoder.inverse_transform(y_testF)\n",
    "\n",
    "# Find indices of misclassified samples\n",
    "misclassified_indices_female = [i for i in range(len(y_test_female)) if y_test_female[i] != y_pred_female[i]]\n",
    "\n",
    "# Print some misclassified samples and their true/predicted labels\n",
    "for idx in misclassified_indices_female[:5]:\n",
    "    print(f\"True Label: {y_test_female[idx]}, Predicted Label: {y_pred_female[idx]}\")\n",
    "    # You can print additional information or visualize the audio data here\n",
    "    # For example, you can use librosa to load and plot the audio sample associated with the misclassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'male_model' is your trained male emotion model\n",
    "# Assuming 'x_testM' and 'y_testM' are your test features and labels for males\n",
    "# Assuming 'encoder' is the OneHotEncoder used for encoding labels\n",
    "\n",
    "# Get predictions for male model\n",
    "pred_test_male = male_model.predict(x_testM)\n",
    "y_pred_male = encoder.inverse_transform(pred_test_male)\n",
    "y_test_male = encoder.inverse_transform(y_testM)\n",
    "\n",
    "# Find indices of misclassified samples\n",
    "misclassified_indices_male = [i for i in range(len(y_test_male)) if y_test_male[i] != y_pred_male[i]]\n",
    "\n",
    "# Print some misclassified samples and their true/predicted labels\n",
    "for idx in misclassified_indices_male[:5]:\n",
    "    print(f\"True Label: {y_test_male[idx]}, Predicted Label: {y_pred_male[idx]}\")\n",
    "    # You can print additional information or visualize the audio data here\n",
    "    # For example, you can use librosa to load and plot the audio sample associated with the misclassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for fine-tuning the female emotion model\n",
    "fine_tune_epochs = 10\n",
    "fine_tune_learning_rate = 0.0001\n",
    "\n",
    "# Create a new instance of the model\n",
    "fine_tuned_female_model = build_model(x_trainF.shape[1])\n",
    "\n",
    "# Compile the model\n",
    "fine_tuned_female_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine_tuned_female = fine_tuned_female_model.fit(x_trainF, y_trainF, batch_size=batch_size,\n",
    "                                                        epochs=fine_tune_epochs, validation_data=(x_testF, y_testF),\n",
    "                                                        callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example for fine-tuning the male emotion model\n",
    "fine_tune_epochs = 10\n",
    "fine_tune_learning_rate = 0.0001\n",
    "\n",
    "# Create a new instance of the model\n",
    "fine_tuned_male_model = build_model(x_trainF.shape[1])\n",
    "\n",
    "# Compile the model\n",
    "fine_tuned_male_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine_tuned_male = fine_tuned_male_model.fit(x_trainF, y_trainF, batch_size=batch_size,\n",
    "                                                        epochs=fine_tune_epochs, validation_data=(x_testF, y_testF),\n",
    "                                                        callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_trainF.shape)  # Assuming x_trainF is your MFCC data for training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Assuming your MFCC data has a shape like (number_of_samples, number_of_mfcc_coefficients, 1)\n",
    "number_of_mfcc_coefficients = 58\n",
    "input_shape = (number_of_mfcc_coefficients, 1)\n",
    "\n",
    "# Create a Conv1D-based model\n",
    "audio_model = models.Sequential([\n",
    "    layers.Conv1D(64, 3, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4, activation='softmax')  # Assuming you have 4 classes (angry, happy, neutral, sad)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "audio_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 30  # Define the number of training epochs\n",
    "\n",
    "# Train the model\n",
    "history_audio_model = audio_model.fit(x_trainF, y_trainF, batch_size=batch_size,\n",
    "                                      epochs=epochs, validation_data=(x_testF, y_testF),\n",
    "                                      callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example for threshold adjustment for female emotion model\n",
    "threshold_female = 0.7  # Experiment with different threshold values\n",
    "\n",
    "# Predictions\n",
    "female_predictions = female_model.predict(x_testF)\n",
    "\n",
    "# Apply threshold\n",
    "female_predictions_adjusted = (female_predictions > threshold_female).astype(int)\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "adjusted_female_accuracy = accuracy_score(y_testF.argmax(axis=1), female_predictions_adjusted.argmax(axis=1))\n",
    "print(f'Accuracy with adjusted threshold for female model: {adjusted_female_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for threshold adjustment for male emotion model\n",
    "threshold_male = 0.7  # Experiment with different threshold values\n",
    "\n",
    "# Predictions\n",
    "male_predictions = male_model.predict(x_testM)\n",
    "\n",
    "# Apply threshold\n",
    "male_predictions_adjusted = (male_predictions > threshold_male).astype(int)\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "adjusted_male_accuracy = accuracy_score(y_testM.argmax(axis=1), male_predictions_adjusted.argmax(axis=1))\n",
    "print(f'Accuracy with adjusted threshold for male model: {adjusted_male_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create a directory to save all models and information\n",
    "save_directory = 'emotion_models'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the female Conv1D model\n",
    "female_model.save(os.path.join(save_directory, 'female_model.h5'))\n",
    "\n",
    "# Save the male Conv1D model\n",
    "male_model.save(os.path.join(save_directory, 'male_model.h5'))\n",
    "\n",
    "total_model.save(os.path.join(save_directory, 'main_mdoels.h5'))\n",
    "\n",
    "# Save the preprocessor using joblib\n",
    "joblib.dump(extract_features, 'extract_features.joblib')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
